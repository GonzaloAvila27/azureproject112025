# azureproject112025

ğŸ§¾ INFORME TÃ‰CNICO

Proyecto: Spotify End-To-End Azure Data Engineering
Entorno: Azure Cloud

1ï¸âƒ£ OBJETIVO DEL PROYECTO

1 Implementar una arquitectura integral de ingenierÃ­a de datos en Azure, aplicando buenas prÃ¡cticas de entornos productivos:
2 Flujo completo Ingesta â†’ Procesamiento â†’ CuraciÃ³n (Bronze â†’ Silver â†’ Gold).
3 IntegraciÃ³n modular de servicios Azure: Data Factory, Data Lake, Databricks y SQL Database.
4 ImplementaciÃ³n de cargas incrementales y metadatos dinÃ¡micos.
5 Control de versiones mediante GitHub y CI/CD.
6 ValidaciÃ³n continua y monitoreo con logging detallado.

Recursos	Data Factory, Data Lake, SQL DB, Databricks	Servicios principales.
Seguridad: autenticaciÃ³n SQL + Entra ID y firewall con IP local.

##  DATOS FUENTE

Tablas creadas desde script SQL en GitHub:
DimArtist, DimUser, DimDate, FactStream, etc.

##  DESARROLLO DEL PIPELINE INCREMENTAL (BRONZE LAYER)
ğŸ”¸ Pipeline principal: Incremental_loop

Objetivo: mover datos desde SQL â†’ Data Lake con control de cambios basado en columna CDC.

# Componentes:

ğŸ” ParÃ¡metro loop_input â†’ array JSON con definiciÃ³n dinÃ¡mica de cada tabla.

ğŸ” ForEach1 (secuencial) â†’ itera sobre cada tabla, garantizando ejecuciÃ³n ordenada.

ğŸ” Lookup last_cdc â†’ obtiene la fecha del Ãºltimo CDC registrada en cdc.json.

ğŸ–¨ Copy azureSQLtoLake â†’ extrae solo filas nuevas.

âœ… IfCondition Ifincrimental_data â†’ evalÃºa si hubo datos nuevos.

â² Script max_cdc â†’ calcula la fecha mÃ¡xima del nuevo lote.

ğŸ–¨ Copy update_last_cdc â†’ actualiza cdc.json con la nueva fecha.

ğŸ—‘ Delete Delete_empty_file â†’ elimina archivos vacÃ­os si no hay nuevos registros.

### ğŸ§  INCIDENTES Y SOLUCIONES TÃ‰CNICAS APLICADAS

Durante la implementaciÃ³n, se detectaron diversos errores de configuraciÃ³n, los cuales se documentan a continuaciÃ³n:

# NÂº DescripciÃ³n del error	Causa raÃ­z	SoluciÃ³n aplicada

â—	Error array index '0' cannot be selected from empty array	El archivo cdc.json no existÃ­a o estaba vacÃ­o, provocando que activity('last_cdc').output.value devolviera un array vacÃ­o.	Se creÃ³ un valor por defecto en caso de CDC vacÃ­o (1900-01-01) y se aÃ±adiÃ³ validaciÃ³n con @if(or(equals(...))).

â—		BadRequest en IfCondition	MÃ©trica usada: dataRead (a veces null).	Se reemplazÃ³ por: @greater(int(coalesce(activity('azureSQLtoLake').output.rowsCopied, 0)), 0) para robustez.

â—		Concurrency alta en ForEach provocaba colisiones	EjecuciÃ³n simultÃ¡nea de tablas.	Se habilitÃ³ modo Secuencial (Concurrency = 1) durante depuraciÃ³n.

ğŸ§© EXPRESIONES CLAVE FINALMENTE ADOPTADAS

## Carga incremental (Copy â€“ azureSQLtoLake):

select *
from @{item().schema}.@{item().table}
where @{item().cdc_col} > '@{variables('cdc_cutoff')}'


## CondiciÃ³n IF:

@greater(int(coalesce(activity('azureSQLtoLake').output.rowsCopied, 0)), 0)


## Ruta dinÃ¡mica en datasets:

@concat(item().table, '_cdc')


ActualizaciÃ³n de CDC (update_last_cdc):

{
  "name": "cdc",
  "value": {
    "value": "@{activity('max_cdc').output.resultSets[0].rows[0].cdc}",
    "type": "Expression"
  }
}

âœ… RESULTADO FINAL ESPERADO

Tras un run , cada carpeta de tabla en el contenedor bronze mantiene:

bronze/
 â”œâ”€â”€ DimUser_cdc/
 â”‚   â”œâ”€â”€ empty.json
 â”‚   â””â”€â”€ cdc.json  â† {"cdc": "2025-11-12T14:38:21Z"}
 â”œâ”€â”€ DimTrack_cdc/
 â”‚   â”œâ”€â”€ empty.json
 â”‚   â””â”€â”€ cdc.json
 ...


En la siguiente ejecuciÃ³n, el Lookup leerÃ¡ esa fecha(actualizada), permitiendo una ingesta incremental totalmente automatizada.
